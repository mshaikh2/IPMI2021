{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from misc.config import Config\n",
    "from trainer import JoImTeR as trainer\n",
    "from sklearn.metrics.pairwise import cosine_similarity,euclidean_distances,cosine_distances\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "# import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "from misc.utils import mkdir_p\n",
    "# from datasets import prepare_data\n",
    "from model import ImageEncoder,TextEncoder\n",
    "import dataset_classification,dataset\n",
    "\n",
    "from transformers import BertConfig\n",
    "from misc.config import Config\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_encoder_classifier = ImageEncoder_Classification(encoder_path='../output/OpenI_test_combo_t4.0s0.5.w0.5_d0.5-01.01.02_2020_12_08_09_25_53/Model/image_encoder.pth', pretrained=True, cfg = cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_parameters = []\n",
    "# for n, p in image_encoder_classifier.named_parameters():\n",
    "#     if 'pretrained_encoder' not in n:\n",
    "#         print(n)\n",
    "#         classification_parameters.append(p)\n",
    "# optim_params = [\n",
    "# {'params':image_encoder_classifier.pretrained_encoder.parameters(), 'lr':5e-6}, \n",
    "# {'params':classification_parameters, 'lr':cfg.lr}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set = dataset_classification.build_dataset('train', cfg)\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#                 data_set, batch_size=2, drop_last=False,\n",
    "#                 shuffle=False, num_workers=2)\n",
    "# data_iter = iter(train_loader)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# total_bce_loss_epoch = 0.0\n",
    "# for epoch in tqdm(range(30)):\n",
    "#     for step in tqdm(range(len(data_iter))):\n",
    "#         imgs, classes = data_iter.next()\n",
    "#         y_pred = image_encoder_classifier(imgs)\n",
    "#         bce_loss = criterion(y_pred,classes)\n",
    "#         bce_loss.backward()\n",
    "#         total_bce_loss_epoch+=bce_loss.item()\n",
    "#         if step==10:\n",
    "#             break\n",
    "#     print(step)\n",
    "#     total_bce_loss_epoch/=step\n",
    "#     print(total_bce_loss_epoch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion()\n",
    "# np.concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.set_device(3)\n",
    "# cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg.CUDA = False\n",
    "np.random.seed(cfg.seed)\n",
    "torch.manual_seed(cfg.seed)\n",
    "if cfg.CUDA:\n",
    "    torch.cuda.manual_seed_all(cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset_classification' from '/home/mingchengao/IPMI2021/code/dataset_classification.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import dataset_classification, dataset\n",
    "\n",
    "reload(dataset_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = dataset.build_dataset('test', cfg)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                data_set, batch_size=100, drop_last=False,\n",
    "                shuffle=False, num_workers=1)\n",
    "data_iter = iter(test_loader)\n",
    "# print('num_batches:',len(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criter\n",
    "# imgs, classes = data_iter.next()\n",
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1196\n"
     ]
    }
   ],
   "source": [
    "print(data_set.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1\n",
    "# nb_digits = 7\n",
    "# # Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "# y = torch.tensor([7,2])\n",
    "# # One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "# y_onehot = torch.FloatTensor(nb_digits).zero_()\n",
    "# print(y_onehot)\n",
    "# y_onehot.scatter_(0,y,1)\n",
    "\n",
    "# print(y)\n",
    "# print(y_onehot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "bert_config = BertConfig(vocab_size=test_loader.dataset.vocab_size, hidden_size=512, num_hidden_layers=3,\n",
    "                    num_attention_heads=8, intermediate_size=2048, hidden_act='gelu',\n",
    "                    hidden_dropout_prob=cfg.hidden_dropout_prob, attention_probs_dropout_prob=cfg.attention_probs_dropout_prob,\n",
    "                    max_position_embeddings=512, layer_norm_eps=1e-12,\n",
    "                    initializer_range=0.02, type_vocab_size=2, pad_token_id=0)\n",
    "\n",
    "def build_model(cfg):\n",
    "    image_encoder = ImageEncoder(output_channels=cfg.hidden_dim)\n",
    "\n",
    "    if cfg.text_encoder_path != '':\n",
    "\n",
    "        img_encoder_path = cfg.text_encoder_path.replace('text_encoder', 'image_encoder')\n",
    "#         print('Load image encoder from:', img_encoder_path)\n",
    "        state_dict = torch.load(img_encoder_path, map_location='cpu')\n",
    "        if 'model' in state_dict.keys():\n",
    "            image_encoder.load_state_dict(state_dict['model'])\n",
    "        else:\n",
    "            image_encoder.load_state_dict(state_dict)\n",
    "    for p in image_encoder.parameters(): # make image encoder grad on\n",
    "        p.requires_grad = False\n",
    "\n",
    "\n",
    "    #         image_encoder.eval()\n",
    "    epoch = 0\n",
    "\n",
    "    ###################################################################\n",
    "    text_encoder = TextEncoder(bert_config = bert_config)\n",
    "    if cfg.text_encoder_path != '':\n",
    "        text_encoder_path = cfg.text_encoder_path\n",
    "#         print('Load text encoder from:', text_encoder_path)\n",
    "        state_dict = torch.load(text_encoder_path, map_location='cpu')\n",
    "        if 'model' in state_dict.keys():\n",
    "            text_encoder.load_state_dict(state_dict['model'])\n",
    "        else:\n",
    "            text_encoder.load_state_dict(state_dict)\n",
    "    for p in text_encoder.parameters(): # make text encoder grad on\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # ########################################################### #\n",
    "    if cfg.CUDA:\n",
    "        text_encoder = text_encoder.cuda()\n",
    "        image_encoder = image_encoder.cuda()\n",
    "    return text_encoder.eval(),image_encoder.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/OpenI_test_combo_t4.0s0.5.w0.5_d0.75-01.01.02_2020_12_08_18_05_34/Model/text_encoder.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:38<01:35, 19.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/OpenI_test_combo_t4.0s0.5.w0.5_d0.5-01.01.02_2020_12_08_09_25_53/Model/text_encoder.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [01:16<01:39, 24.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/OpenI_test_combo_t2.0s0.5.w0.5_d0.75-01.01.02_2020_12_07_01_13_05/Model/text_encoder300.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [01:51<00:45, 22.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/OpenI_test_combo_t4.0s0.5.w0.5_d1.0-01.01.02_2020_12_07_01_11_56/Model/text_encoder300.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:26<00:00, 20.97s/it]\n"
     ]
    }
   ],
   "source": [
    "tp1_arr = []\n",
    "tp5_arr = []\n",
    "tp10_arr = []\n",
    "tp1_arr_t = []\n",
    "tp5_arr_t = []\n",
    "tp10_arr_t = []\n",
    "run_arr = []\n",
    "for run in tqdm(os.listdir('../output')):\n",
    "    if 'test' in run:\n",
    "    # for run in tqdm(['OpenI_test_combo_t4.0s0.5.w0.5_d0.75-01.01.02_2020_12_08_18_05_34/']):\n",
    "        cos = None\n",
    "\n",
    "        cfg.text_encoder_path = os.path.join('../output',run,'Model',os.listdir(os.path.join('../output',run,'Model'))[0].replace('image','text'))\n",
    "\n",
    "        print(cfg.text_encoder_path)\n",
    "\n",
    "        text_encoder, image_encoder = build_model(cfg)\n",
    "\n",
    "        data_iter = iter(test_loader)\n",
    "    #     print('num_batches:',len(data_iter))\n",
    "\n",
    "\n",
    "        for step in range(len(data_iter)):\n",
    "            imgs, captions, masks, class_ids, cap_lens = data_iter.next()\n",
    "            class_ids = class_ids.numpy()\n",
    "\n",
    "            if cfg.CUDA:\n",
    "                imgs, captions, masks, cap_lens = imgs.cuda(), captions.cuda(), masks.cuda(), cap_lens.cuda()\n",
    "        #     b, n, l = captions.shape\n",
    "            r_feats, v_feats = image_encoder(imgs)\n",
    "            w_feats, s_feats = text_encoder(captions,masks)\n",
    "            v_feats = v_feats.detach().cpu().numpy()\n",
    "            s_feats = s_feats.detach().cpu().numpy()\n",
    "\n",
    "            if cos is None:\n",
    "                cos = cosine_similarity(v_feats,s_feats)\n",
    "                cos_t = cosine_similarity(s_feats,v_feats)\n",
    "            else:\n",
    "                cos = np.concatenate([cos,cosine_similarity(v_feats,s_feats)],axis = 0)\n",
    "                cos_t = np.concatenate([cos_t,cosine_similarity(s_feats,v_feats)],axis = 0)\n",
    "        #     print(len(cos))\n",
    "                    # len(dataset.wordtoix)\n",
    "        total_count=len(cos)\n",
    "    #     print(total_count)\n",
    "        cos = np.array(cos) #i2t\n",
    "\n",
    "        gt = np.concatenate(np.repeat([range(test_loader.batch_size)],cos.shape[0]/test_loader.batch_size,axis=0))\n",
    "        run_arr.append(','.join(run.split('_')[2:5]))\n",
    "    #     print(cos.shape)\n",
    "\n",
    "        # i2t r@100\n",
    "        tp = cos.argsort()[:,-10:][:,::-1]\n",
    "        tp_arr = []\n",
    "        for i in range(10):\n",
    "            tp_arr.append(np.array(tp[:,i]))\n",
    "\n",
    "\n",
    "        t1,t5,t10=0,0,0\n",
    "        for i in range(10):\n",
    "            if i==0:\n",
    "    #             print(i,'top1')\n",
    "                t1=((gt == tp_arr[i]).sum())\n",
    "                t5 = t1\n",
    "            elif i>0 and i<5:\n",
    "    #             print(i,'top5')\n",
    "                t5+=((gt == tp_arr[i]).sum())\n",
    "                t10 = t5\n",
    "            elif i>4:\n",
    "    #             print(i,'top10')\n",
    "                t10+=((gt == tp_arr[i]).sum())\n",
    "\n",
    "        tp1_arr.append(t1*100/total_count)\n",
    "        tp5_arr.append(t5*100/total_count)\n",
    "        tp10_arr.append(t10*100/total_count)\n",
    "\n",
    "        # t2i r@100\n",
    "        cos_t = np.array(cos_t)\n",
    "        tp = cos_t.argsort()[:,-10:][:,::-1]\n",
    "        tp_arr = []\n",
    "        for i in range(10):\n",
    "            tp_arr.append(np.array(tp[:,i]))\n",
    "\n",
    "\n",
    "        t1,t5,t10=0,0,0\n",
    "        for i in range(10):\n",
    "            if i==0:\n",
    "    #             print(i,'top1')\n",
    "                t1=((gt == tp_arr[i]).sum())\n",
    "                t5 = t1\n",
    "            elif i>0 and i<5:\n",
    "    #             print(i,'top5')\n",
    "                t5+=((gt == tp_arr[i]).sum())\n",
    "                t10 = t5\n",
    "            elif i>4:\n",
    "    #             print(i,'top10')\n",
    "                t10+=((gt == tp_arr[i]).sum())\n",
    "\n",
    "        tp1_arr_t.append(t1*100/total_count)\n",
    "        tp5_arr_t.append(t5*100/total_count)\n",
    "        tp10_arr_t.append(t10*100/total_count)\n",
    "    \n",
    "#     'top1:{0:.4f}, top2:{1:.4f}, top3:{2:.4f}'.format(((gt == tp1).sum())/total_count,((gt == tp2).sum()+(gt == tp1).sum())/total_count,((gt == tp3).sum()+(gt == tp2).sum()+(gt == tp1).sum())/total_count)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/OpenI_test_combo_t4.0s0.5.w0.5_d1.0-01.01.02_2020_12_07_01_11_56/Model/text_encoder300.pth\n"
     ]
    }
   ],
   "source": [
    "print(cfg.text_encoder_path)\n",
    "# cos,cos_t\n",
    "# tp_arr[i].shape\n",
    "# gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_encoder.pth']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.listdir(os.path.join('../output',run,'Model'))[0]\n",
    "os.listdir(os.path.join('../output',run,'Model'))\n",
    "# os.listdir('../output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g1,g2,g3</th>\n",
       "      <th>i2t_tp1</th>\n",
       "      <th>i2t_tp5</th>\n",
       "      <th>i2t_tp10</th>\n",
       "      <th>t2i_tp1</th>\n",
       "      <th>t2i_tp5</th>\n",
       "      <th>t2i_tp10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combo,t2.0s0.5.w0.5,d0.75-01.01.02</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combo,t4.0s0.5.w0.5,d0.5-01.01.02</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>combo,t4.0s0.5.w0.5,d0.75-01.01.02</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>combo,t4.0s0.5.w0.5,d1.0-01.01.02</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>25.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             g1,g2,g3   i2t_tp1    i2t_tp5   i2t_tp10  \\\n",
       "2  combo,t2.0s0.5.w0.5,d0.75-01.01.02  3.333333  16.333333  29.000000   \n",
       "1   combo,t4.0s0.5.w0.5,d0.5-01.01.02  3.333333  13.000000  25.333333   \n",
       "0  combo,t4.0s0.5.w0.5,d0.75-01.01.02  1.666667  13.333333  27.000000   \n",
       "3   combo,t4.0s0.5.w0.5,d1.0-01.01.02  5.666667  16.000000  28.666667   \n",
       "\n",
       "    t2i_tp1    t2i_tp5   t2i_tp10  \n",
       "2  4.666667  16.000000  28.000000  \n",
       "1  3.666667  14.333333  28.000000  \n",
       "0  3.000000  15.666667  28.000000  \n",
       "3  5.333333  16.333333  25.666667  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results['g1,g2,g3'] = run_arr\n",
    "\n",
    "df_results['i2t_tp1'] = tp1_arr\n",
    "df_results['i2t_tp5'] = tp5_arr\n",
    "df_results['i2t_tp10'] = tp10_arr\n",
    "df_results['t2i_tp1'] = tp1_arr_t\n",
    "df_results['t2i_tp5'] = tp5_arr_t\n",
    "df_results['t2i_tp10'] = tp10_arr_t\n",
    "df_results.sort_values(by=['g1,g2,g3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g1,g2,g3</th>\n",
       "      <th>i2t_tp1</th>\n",
       "      <th>i2t_tp5</th>\n",
       "      <th>i2t_tp10</th>\n",
       "      <th>t2i_tp1</th>\n",
       "      <th>t2i_tp5</th>\n",
       "      <th>t2i_tp10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>combo,t4.0s0.5.w0.5,d0.5-01.01.02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            g1,g2,g3  i2t_tp1    i2t_tp5   i2t_tp10   t2i_tp1  \\\n",
       "0  combo,t4.0s0.5.w0.5,d0.5-01.01.02      4.0  15.333333  25.666667  6.333333   \n",
       "\n",
       "     t2i_tp5  t2i_tp10  \n",
       "0  14.666667      24.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results['g1,g2,g3'] = run_arr\n",
    "\n",
    "df_results['i2t_tp1'] = tp1_arr\n",
    "df_results['i2t_tp5'] = tp5_arr\n",
    "df_results['i2t_tp10'] = tp10_arr\n",
    "df_results['t2i_tp1'] = tp1_arr_t\n",
    "df_results['t2i_tp5'] = tp5_arr_t\n",
    "df_results['t2i_tp10'] = tp10_arr_t\n",
    "df_results.sort_values(by=['g1,g2,g3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g1,g2,g3</th>\n",
       "      <th>i2t_tp1</th>\n",
       "      <th>i2t_tp5</th>\n",
       "      <th>i2t_tp10</th>\n",
       "      <th>t2i_tp1</th>\n",
       "      <th>t2i_tp5</th>\n",
       "      <th>t2i_tp10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>only.s.triplet,01.01,04</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  g1,g2,g3   i2t_tp1  i2t_tp5   i2t_tp10  t2i_tp1   t2i_tp5  \\\n",
       "0  only.s.triplet,01.01,04  3.666667     13.0  26.333333      3.0  9.333333   \n",
       "\n",
       "   t2i_tp10  \n",
       "0      22.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame()\n",
    "df_results['g1,g2,g3'] = run_arr\n",
    "\n",
    "df_results['i2t_tp1'] = tp1_arr\n",
    "df_results['i2t_tp5'] = tp5_arr\n",
    "df_results['i2t_tp10'] = tp10_arr\n",
    "df_results['t2i_tp1'] = tp1_arr_t\n",
    "df_results['t2i_tp5'] = tp5_arr_t\n",
    "df_results['t2i_tp10'] = tp10_arr_t\n",
    "df_results.sort_values(by=['g1,g2,g3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = pd.DataFrame()\n",
    "# df_results['g1,g2,g3'] = run_arr\n",
    "# df_results['tp1'] = tp1_arr\n",
    "# df_results['tp2'] = tp2_arr\n",
    "# df_results['tp3'] = tp3_arr\n",
    "# df_results.sort_values(by=['g1,g2,g3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results['g1,g2,g3'] = run_arr\n",
    "# df_results['tp1'] = tp1_arr\n",
    "# df_results['tp2'] = tp2_arr\n",
    "# df_results['tp3'] = tp3_arr\n",
    "# df_results.sort_values(by=['g1,g2,g3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results.sort_values(by=['g1,g2,g3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.sort_values(by=['g1,g2,g3']).to_csv('../data/r_i2t_t2i_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos = np.array(cos)\n",
    "# # cos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = cos.argsort()[:,-3:][:,::-1]\n",
    "# tp1 = np.array(tp[:,0])\n",
    "# tp2 = np.array(tp[:,1])\n",
    "# tp3 = np.array(tp[:,2])\n",
    "# gt = np.concatenate(np.repeat([range(100)],cos.shape[0]/100,axis=0))\n",
    "# 'top1:{0:.4f}, top2:{1:.4f}, top3:{2:.4f}'.format(((gt == tp1).sum())/total_count,((gt == tp2).sum()+(gt == tp1).sum())/total_count,((gt == tp3).sum()+(gt == tp2).sum()+(gt == tp1).sum())/total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_feats.shape, v_feats.shape, w_feats.shape, s_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for step in tqdm(range(len(data_iter))):\n",
    "#     imgs, captions, masks, class_ids, cap_lens = data_iter.next()\n",
    "#     class_ids = class_ids.numpy()\n",
    "\n",
    "# #     if cfg.CUDA:\n",
    "# #         imgs, captions, masks, cap_lens = imgs.cuda(), captions.cuda(), masks.cuda(), cap_lens.cuda()\n",
    "# #     b, n, l = captions.shape\n",
    "#     r_feats, v_feats = image_encoder(imgs)\n",
    "#     w_feats, s_feats = text_encoder(captions,masks)\n",
    "#     v_feats = v_feats.detach().cpu().numpy()\n",
    "#     s_feats = s_feats.detach().cpu().numpy()\n",
    "#     cos = cosine_similarity(v_feats,s_feats)\n",
    "#     cos = np.array(cos)\n",
    "#     print(cos.shape)\n",
    "#     total_count = 100\n",
    "#     tp = cos.argsort()[:,-3:][:,::-1]\n",
    "#     tp1 = np.array(tp[:,0])\n",
    "#     tp2 = np.array(tp[:,1])\n",
    "#     tp3 = np.array(tp[:,2])\n",
    "#     gt = np.zeros(cos.shape[0], dtype='int')\n",
    "#     print('top1:{0}, top2:{1}, top3:{2}'.format(((gt == tp1).sum())/total_count,((gt == tp2).sum()+(gt == tp1).sum())/total_count,((gt == tp3).sum()+(gt == tp2).sum()+(gt == tp1).sum())/total_count))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow((imgs[0].squeeze(0).detach().cpu().numpy()+1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ' '.join([data_set.idx2word[x] for x in captions[0][:masks[0].sum()].detach().cpu().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ' '.join([data_set.idx2word[x] for x in captions[59][:masks[59].sum()].detach().cpu().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_count = 100\n",
    "# tp = cos.argsort()[:,-3:][:,::-1]\n",
    "# tp1 = np.array(tp[:,0])\n",
    "# tp2 = np.array(tp[:,1])\n",
    "# tp3 = np.array(tp[:,2])\n",
    "# gt = np.zeros(cos.shape[0], dtype='int')\n",
    "# 'top1:{0}, top2:{1}, top3:{2}'.format(((gt == tp1).sum())/total_count,((gt == tp2).sum()+(gt == tp1).sum())/total_count,((gt == tp3).sum()+(gt == tp2).sum()+(gt == tp1).sum())/total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp = cos.argsort()[:,-10:][:,::-1] // 5\n",
    "# # tp1 = np.array(tp[:,0])\n",
    "# # tp2 = np.array(tp[:,1])\n",
    "# # tp3 = np.array(tp[:,2])\n",
    "# # tp4 = np.array(tp[:,3])\n",
    "# # tp5 = np.array(tp[:,4])\n",
    "# sn = tp.shape[0]\n",
    "# gt = np.repeat(np.arange(sn).reshape(sn,1), 10, axis=1)\n",
    "# hits = np.equal(tp,gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top1 = hits[:,:1].any(axis=1).sum() / hits.shape[0]\n",
    "# top5 = hits[:,:5].any(axis=1).sum() / hits.shape[0]\n",
    "# top10 = hits[:,:10].any(axis=1).sum() / hits.shape[0]\n",
    "# print('top1: %.4f, top5: %.4f, top10: %.4f' % (top1, top5, top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt.shape,cos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = imgs[-1][8].detach().cpu().numpy() \n",
    "# print(a.min(),a.max())\n",
    "# a = (a - a.min()) / (a.max()-a.min())\n",
    "# print(a.min(),a.max())\n",
    "# plt.imshow(np.rollaxis(a=a,axis=0,start=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [dataset.ixtoword[x] for x in captions[8].detach().cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs[0].shape,imgs[1].shape,imgs[].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.dot()\n",
    "# positive_pair - reduce the dot\n",
    "# negative_pair - increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array(list(range(32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(prob)/sum(np.exp(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_id = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_id = np.random.choice(np.array(ids),size=1)[0]\n",
    "while neg_id==cur_id:\n",
    "    neg_id = np.random.choice(np.array(ids),size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(np.array(ids),size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_ids = torch.tensor([np.random.choice(ids[ids!=x]) for x in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29, 15, 11,  8, 29, 21,  7, 26, 19, 23, 11, 10, 24, 21,  3,  7, 24,  2,\n",
       "        22, 21,  1, 24, 11, 30,  5,  1, 28, 20,  0, 11, 25, 21])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(np.array([1,2,3,4]))\n",
    "b = torch.tensor(np.array([2,4,6,8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss_with_distance_fn(distance_fn, anc, pos, neg, margin=0.5):\n",
    "    score = distance_fn(anc,pos) - distance_fn(anc,neg) + margin\n",
    "    z = torch.zeros_like(score)\n",
    "    return torch.max(score,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-b251c1415739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'top_5' is not defined"
     ]
    }
   ],
   "source": [
    "top_5,top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_100 = pd.read_csv('../data/r_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "most common triplet loss\n",
    "32 image text pairs\n",
    "1 image as anchor - 1st text +ve sample - random sample 1 -ve sample from remaining 31 samples \n",
    "\n",
    "expecially in medical - no problem - is much large\n",
    "                        problem - less\n",
    "                        chance of -ve sample +ve sample being no problem high\n",
    "                        solution: N-paired\n",
    "                        \n",
    "\n",
    "\n",
    "N paired triplet loss\n",
    "\n",
    "-- table to select hyper param\n",
    "1. w1.5s0.5 IU - 3 triplet - top 1\n",
    "2. R@1, 5 , 10 (100) -  find 5\n",
    "2.1. transpose matrix to get t2i as well\n",
    "3. top 5 damsm add basic triplet top 1 - get idea after 2\n",
    "4. top 1 damsm with N-paired triplet\n",
    "----------------------------------------\n",
    "-- find best - final ablation table\n",
    "5. only with s_loss\n",
    "6. only with s_triplet\n",
    "7. MIMIC - s_loss, s_triplet alone\n",
    "----------------------------------------\n",
    "8. MIMIC learning rate 1e-4  works well\n",
    "\n",
    "--------------------------------------\n",
    "9. IU Classification data - make (use only 14 labels from the MIMIC)\n",
    "10. Paper Diagram - make\n",
    "\n",
    "11. IU/MIMIC classifcation comparable paper? \n",
    "12. Classification on IU - 3\n",
    "13. Classifiaction on MIMIC - 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4. Mimic - try the best settings on IU, (finetune) -> R@1K\n",
    "    i. only attnGAN - s_loss\n",
    "    ii. attnGAN - s_loss + \n",
    "\n",
    "\n",
    "Downstream:\n",
    "    Classification :\n",
    "        IU,MIMIC:\n",
    "            Image - with random init image encoder\n",
    "            Image - with our pretrained frozen image encoder  - [fc1 (256) - act(relu) - do - fc2 (14) - act(sm)] - non-trainable\n",
    "            Image - [with our pretrained trainable image encoder - fc1 (256) - act(relu) - do - fc2 (14) - act(sm)] - trainable\n",
    "        \n",
    "            \n",
    "        \n",
    "    I2T - R-Prec and T2I:\n",
    "        IU - top 7 results from r-prec - top 1, top5, top 10\n",
    "        MIMIC - top 2 3 - top 1, top5, top 10\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98547063, 0.98325963, 0.97283639, 0.96746684, 0.95672773,\n",
       "       0.91629817, 0.90840177])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_c = np.array([46,53,86,103,137,265,290])\n",
    "Q = 3166.0\n",
    "weight_vector = (Q - Q_c)/Q\n",
    "weight_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load('../output/OpenI_classification_raw_2020_12_08_23_04_51/Model/image_encoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
